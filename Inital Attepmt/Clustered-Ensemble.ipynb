{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit.quantum_info import Statevector\n",
    "from scipy.stats import unitary_group\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "from scipy.optimize import minimize\n",
    "from IPython.display import clear_output\n",
    "\n",
    "plt.style.use(['ieee', 'no-latex'])\n",
    "\n",
    "sim = AerSimulator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "na = 1\n",
    "n_tot = n + na\n",
    "T = 20\n",
    "L = 4\n",
    "Ndata = 100\n",
    "Nparams = 2 * L * n_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haarSample(Ndata, seed):\n",
    "    np.random.seed(seed)\n",
    "    states_T = [unitary_group.rvs(2**n)[:, 0] for _ in range(Ndata)]\n",
    "    return states_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffusionCircuit(t, input_state, phis, gs=None):\n",
    "\n",
    "    qc = QuantumCircuit(n)\n",
    "    qc.initialize(input_state, range(n), normalize=True)\n",
    "    \n",
    "    for tt in range(t):\n",
    "        for i in range(n):\n",
    "            qc.rz(phis[3 * n * tt + i], i)\n",
    "            qc.ry(phis[3 * n * tt + n + i], i)\n",
    "            qc.rz(phis[3 * n * tt + 2 * n + i], i)\n",
    "        if n >= 2:\n",
    "            for i, j in combinations(range(n), 2):\n",
    "                qc.rzz(gs[tt] / (2 * np.sqrt(n)), i, j)\n",
    "\n",
    "    qc.save_statevector()\n",
    "    result = sim.run(qc).result()\n",
    "    return Statevector(result.get_statevector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffusionData(t, inputs, diff_hs, seed):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Generate random angles for the rotations and gates\n",
    "    phis = (np.random.rand(Ndata, 3 * n * t) * np.pi / 4 - np.pi / 8) * diff_hs.repeat(3 * n)\n",
    "    if n > 1:\n",
    "        gs = (np.random.rand(Ndata, t) * 0.2 + 0.4) * diff_hs\n",
    "    else:\n",
    "        gs = None\n",
    "\n",
    "\n",
    "    states = np.zeros((Ndata, 2**n), dtype=np.complex128)\n",
    "\n",
    "    # Fill the states array by applying the scramble circuit\n",
    "    for i in range(Ndata):\n",
    "        states[i] = diffusionCircuit(t, inputs[i], phis[i], gs[i] if gs is not None else None).data\n",
    "\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster0Gen(n, N_train, scale, seed=None):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    remains = np.random.randn(N_train, 2**n - 1) + 1j * np.random.randn(N_train, 2**n - 1)\n",
    "    states = np.hstack((np.ones((N_train, 1)), scale * remains))\n",
    "    \n",
    "    norms = np.linalg.norm(states, axis=1, keepdims=True)\n",
    "    states /= norms\n",
    "    \n",
    "    return states.astype(np.complex64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate diffusion data set\n",
    "diff_hs = np.linspace(1.0, 4.0, T)\n",
    "\n",
    "X = cluster0Gen(n, Ndata, 0.08, seed=12)\n",
    "S = np.zeros((T + 1, Ndata, 2**n), dtype=np.complex64)\n",
    "S[0] = X\n",
    "\n",
    "for t in range(1, T + 1):\n",
    "    S[t] = diffusionData(t, X, diff_hs[:t], seed=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stateToBloch(statevector):\n",
    "    alpha, beta = statevector[0], statevector[1]\n",
    "    \n",
    "    x = 2 * np.real(alpha * np.conj(beta))\n",
    "    y = 2 * np.imag(alpha * np.conj(beta))\n",
    "    z = np.abs(alpha)**2 - np.abs(beta)**2\n",
    "    \n",
    "    return x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qutip import Bloch\n",
    "\n",
    "time_steps = [0,5,10,15,20]\n",
    "fig, axs = plt.subplots(1, len(time_steps), subplot_kw={'projection': '3d'}, figsize=(3 * len(time_steps), len(time_steps)))\n",
    "\n",
    "for idx, t in enumerate(time_steps):\n",
    "    pure = []\n",
    "    b = Bloch(axes=axs[idx])\n",
    "    for i in range(Ndata):\n",
    "        b.add_points(stateToBloch(S[t][i]))\n",
    "        b.point_color = ['r']\n",
    "        b.frame_alpha = 0.1\n",
    "        b.sphere_alpha = 0.1\n",
    "        b.point_marker = ['s']\n",
    "        b.point_size = [3]\n",
    "\n",
    "    b.render()\n",
    "    axs[idx].set_title(f\"t = {t}\", loc='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomMeasure(input_state):\n",
    "    reshaped = input_state.reshape(2**na, 2**n)\n",
    "    m_probs = np.sum(np.abs(reshaped)**2, axis=1)  # probabilities of ancilla states\n",
    "    m_probs = m_probs / np.sum(m_probs)  # Normalise probabilities \n",
    "\n",
    "    m_res = np.random.choice(len(m_probs), p=m_probs)  # Measure and select an ancilla state\n",
    "    indices = 2**n * m_res + np.arange(2**n)  # Index of post-measurement state\n",
    "\n",
    "    post_state = input_state[indices]  # Select the corresponding post-measurement state\n",
    "\n",
    "    # Normalize the post-measurement state\n",
    "    norm = np.linalg.norm(post_state)\n",
    "    if norm == 0:\n",
    "        norm = 1  # Avoid division by zero\n",
    "    normalized_state = post_state / norm\n",
    "    return normalized_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoisingLayer(input_state, params, n_tot, L):\n",
    "\n",
    "    qc = QuantumCircuit(n_tot)\n",
    "\n",
    "    qc.initialize(input_state, range(n_tot), normalize=True)\n",
    "\n",
    "    # Apply layers of gates\n",
    "    for l in range(L):\n",
    "        for i in range(n_tot):\n",
    "            qc.rx(params[2 * n_tot * l + i], i)\n",
    "            qc.ry(params[2 * n_tot * l + n_tot + i], i)\n",
    "        for i in range(n_tot // 2):\n",
    "            qc.cz(2 * i, 2 * i + 1)\n",
    "        if n_tot % 2 == 1:\n",
    "            qc.cz(n_tot - 2, n_tot - 1)\n",
    "    \n",
    "    # Save statevector and run the simulation\n",
    "    qc.save_statevector()\n",
    "    result = sim.run(qc).result()\n",
    "    state = result.get_statevector()\n",
    "\n",
    "    # Return the final state as a Statevector\n",
    "    return randomMeasure(state.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc = np.zeros(2**na)\n",
    "anc[0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoisingFull(input_state, params, n_tot, L, t):\n",
    "    '''\n",
    "    SINGLE STATE, RETURN FINAL STATE AFTER MEASUREMENT (N_TOT QUBITS)\n",
    "    '''\n",
    "    x = []\n",
    "    x.append(input_state) \n",
    "    for t in range(T,t-1,-1):\n",
    "        p = params[(T-t) * Nparams : (T-t+1) * Nparams]\n",
    "        outcome = denoisingLayer(x[-1], p, n_tot, L)\n",
    "        x.append(np.kron(outcome[outcome!=0], anc))\n",
    "    return x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ApproxS = [None] * (T+1)\n",
    "ApproxS[-1] = haarSample(Ndata,seed=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxMeanDiscripency(set1, set2):\n",
    "    set1 = np.array(set1, dtype=np.complex128)\n",
    "    set2 = np.array(set2, dtype=np.complex128)\n",
    "    \n",
    "    r11 = 1 - np.mean(np.abs(set1 @ set1.conj().T)**2)\n",
    "    r22 = 1 - np.mean(np.abs(set2 @ set2.conj().T)**2)\n",
    "    r12 = 1 - np.mean(np.abs(set1 @ set2.conj().T)**2)\n",
    "    return 2 * r12 - r11 - r22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ancilla = np.zeros(2**na)\n",
    "ancilla[0] = 1\n",
    "loss_hist = []\n",
    "\n",
    "theta = np.random.uniform(0,2*np.pi, T * Nparams)\n",
    "\n",
    "def costFunction(params, t):\n",
    "    output = []\n",
    "    ApproxS[t-1] = []\n",
    "    for i in range(Ndata):\n",
    "        input = np.kron(ApproxS[T][i], ancilla)\n",
    "        input = input / np.linalg.norm(input)\n",
    "        temp = denoisingFull(input, np.array(theta[0: (T-t+1) * Nparams]), n_tot, L, t+1)\n",
    "        output.append(denoisingLayer(temp, np.array(params), n_tot, L))\n",
    "        output[i] = output[i] / np.linalg.norm(output[i])\n",
    "        ApproxS[t-1].append(output[i][output[i]!=0])\n",
    "\n",
    "    cost = maxMeanDiscripency(ApproxS[t-1], S[t-1])\n",
    "    loss_hist.append(cost)\n",
    "\n",
    "    # Clear output and update the real-time plot\n",
    "    clear_output(wait=True)\n",
    "    plt.xlabel(\"Training Step\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylabel(r\"$\\mathcal{D}_{\\text{MMD}} (\\tilde{\\mathcal{S}}_t, \\mathcal{S}_t)$\")\n",
    "    plt.plot(range(len(loss_hist)), loss_hist)\n",
    "    plt.title(f\"Current Step: {t}\")\n",
    "    plt.show()\n",
    "\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in np.arange(T,0,-1):\n",
    "    result = minimize(\n",
    "        costFunction,\n",
    "        theta[0 : (T-k+1) * Nparams],\n",
    "        args=(k,),\n",
    "        method=\"COBYLA\",\n",
    "        options={\"maxiter\": 100},\n",
    "    )\n",
    "\n",
    "    theta[0 : (T-k+1) * Nparams] = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Training Step\")\n",
    "#plt.yscale('log')\n",
    "plt.ylabel(r'$\\mathcal{D}_{\\text{MMD}} (\\tilde{\\mathcal{S}}_t, \\mathcal{S}_t)$')\n",
    "plt.plot(range(len(loss_hist)), loss_hist)\n",
    "\n",
    "secax = plt.gca().secondary_xaxis('top')\n",
    "secax.set_xlabel(fr\"Diffusion Step $t$\")\n",
    "secax.set_xticklabels(np.arange(T+5,-1,-5))\n",
    "#plt.savefig('Final-Clustering-Loss-500epochs.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testS = [None] * (T+1)\n",
    "\n",
    "testS[T] = haarSample(Ndata, seed=28)\n",
    "\n",
    "for t in range(T,0,-1):\n",
    "    testS[t-1] = []\n",
    "    for i in range(Ndata):\n",
    "        input = np.kron(testS[T][i], ancilla)\n",
    "        input = input / np.linalg.norm(input)\n",
    "        temp = denoisingFull(input, np.array(theta[0: (T-t+1) * Nparams]), n_tot, L, t)\n",
    "        testS[t-1].append(temp[temp!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = [0,5,10,15,20]\n",
    "fig, axs = plt.subplots(3, len(time_steps), subplot_kw={'projection': '3d'}, figsize=( 2 * len(time_steps), len(time_steps)))\n",
    "\n",
    "for idx, t in enumerate(time_steps):\n",
    "    b0 = Bloch(axes=axs[0,idx])\n",
    "    b1 = Bloch(axes=axs[1,idx])\n",
    "    b2 = Bloch(axes=axs[2,idx])\n",
    "    for i in range(Ndata):\n",
    "        b0.add_points(stateToBloch(S[t][i]))\n",
    "        b0.point_color = ['r']\n",
    "        b0.point_size = [3]\n",
    "        b0.frame_alpha = 0.1\n",
    "        b0.sphere_alpha = 0.1\n",
    "        b0.point_marker = ['s']\n",
    "\n",
    "        b1.add_points(stateToBloch(ApproxS[t][i]))\n",
    "        b1.point_color = ['b']\n",
    "        b1.point_size = [3]\n",
    "        b1.frame_alpha = 0.1\n",
    "        b1.sphere_alpha = 0.1\n",
    "        b1.point_marker = ['s']\n",
    "\n",
    "        b2.add_points(stateToBloch(testS[t][i]))\n",
    "        b2.point_color = ['g']\n",
    "        b2.point_size = [3]\n",
    "        b2.frame_alpha = 0.1\n",
    "        b2.sphere_alpha = 0.1\n",
    "        b2.point_marker = ['s']\n",
    "\n",
    "    b0.render()\n",
    "    b1.render()\n",
    "    b2.render()\n",
    "    axs[0,idx].set_title(f\"t = {t}\", loc='left')\n",
    "\n",
    "#plt.savefig('Final-Clustering-BlochSpheres-500epochs.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(T+1), [0.5] * (T+1), 'k--')\n",
    "ApproxS = np.array(ApproxS)\n",
    "testS = np.array(testS)\n",
    "\n",
    "ax.plot(range(T+1), np.mean(np.abs(S[:,:,0])**2, axis=1), 'ro-', label=r'Diffusion')\n",
    "ax.plot(range(T+1), np.mean(np.abs(ApproxS[:,:,0])**2, axis=1), 'bo-', label=r'Training')\n",
    "ax.plot(range(T+1), np.mean(np.abs(testS[:,:,0])**2, axis=1), 'go-', label=r'Testing')\n",
    "ax.set_ylabel(r'$F_0$')\n",
    "ax.set_xlabel(r'$t$')\n",
    "ax.legend(loc= 'best')\n",
    "#plt.savefig('Final-Clustering-Fidelity-500epochs.pdf', bbox_inches='tight' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmds = np.zeros((3, 21))\n",
    "for t in range(21):\n",
    "    idx = np.random.choice(S.shape[1], size=100, replace=False)\n",
    "    mmds[0, t] = maxMeanDiscripency(S[0], S[t, idx])\n",
    "    mmds[1, t] = maxMeanDiscripency(S[0], ApproxS[t])\n",
    "    mmds[2, t] = maxMeanDiscripency(S[0], testS[t])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(mmds[0], 'o-', c='r', label=r'Diffusion')\n",
    "ax.plot(mmds[1], 'o-', c='b', label=r'Training')\n",
    "ax.plot(mmds[2], 'o-', c='g', label=r'Testing')\n",
    "\n",
    "ax.legend(loc = 'best')\n",
    "ax.set_xlabel(r'Diffusion Steps')\n",
    "ax.set_ylabel(r'$\\mathcal{D}_{\\rm MMD}(\\tilde{\\mathcal{S}}_t, \\mathcal{E}_0)$')\n",
    "#plt.savefig('Final-Clustering-DistanceInitial-500epochs.pdf', bbox_inches='tight' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
